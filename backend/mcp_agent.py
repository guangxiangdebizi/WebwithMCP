# mcp_agent.py
"""
MCPæ™ºèƒ½ä½“å°è£… - ä¸ºWebåç«¯ä½¿ç”¨
åŸºäº test.py ä¸­çš„ SimpleMCPAgentï¼Œä¼˜åŒ–ä¸ºé€‚åˆWebSocketæµå¼æ¨é€çš„ç‰ˆæœ¬
"""

import os
import json
import asyncio
from typing import Dict, List, Any, AsyncGenerator
from pathlib import Path
from datetime import datetime, timedelta

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage
from langchain_mcp_adapters.client import MultiServerMCPClient

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. å¤§æ¨¡å‹é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_CONFIG = {
    "api_key": "sk-df2c763fc1d14b20b630dc5ac474d8c2",  # â† æ”¹ä¸ºæ‚¨çš„API Key
    "base_url": "https://api.deepseek.com/v1",  # â† æ”¹ä¸ºæ‚¨çš„APIåœ°å€
    "model_name": "deepseek-chat",  # â† æ”¹ä¸ºæ‚¨çš„æ¨¡å‹åç§°
    "temperature": 0.2,
    "timeout": 60
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. MCPé…ç½®ç®¡ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class MCPConfig:
    """MCPé…ç½®ç®¡ç†"""

    def __init__(self, config_file: str = "mcp.json"):
        self.config_file = config_file
        self.default_config = {}

    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if Path(self.config_file).exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")

        # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
        self.save_config(self.default_config)
        return self.default_config

    def save_config(self, config: Dict[str, Any]):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âŒ é…ç½®æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Webç‰ˆMCPæ™ºèƒ½ä½“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class WebMCPAgent:
    """Webç‰ˆMCPæ™ºèƒ½ä½“ - æ”¯æŒæµå¼æ¨é€"""

    def __init__(self):
        # ä¿®å¤ï¼šä½¿ç”¨backendç›®å½•ä¸‹çš„é…ç½®æ–‡ä»¶
        config_path = Path(__file__).parent / "mcp.json"
        self.config = MCPConfig(str(config_path))
        self.llm = None
        self.mcp_client = None
        self.tools = []
        # æ–°å¢ï¼šæŒ‰æœåŠ¡å™¨åˆ†ç»„çš„å·¥å…·å­˜å‚¨
        self.tools_by_server = {}
        self.server_configs = {}

        # è®¾ç½®APIç¯å¢ƒå˜é‡
        os.environ["OPENAI_API_KEY"] = MODEL_CONFIG["api_key"]
        os.environ["OPENAI_BASE_URL"] = MODEL_CONFIG["base_url"]

    async def initialize(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“"""
        try:
            # åˆå§‹åŒ–å¤§æ¨¡å‹
            self.llm = ChatOpenAI(
                model_name=MODEL_CONFIG["model_name"],
                temperature=MODEL_CONFIG["temperature"],
                request_timeout=MODEL_CONFIG["timeout"],
                max_retries=3,
            )

            # åŠ è½½MCPé…ç½®å¹¶è¿æ¥
            mcp_config = self.config.load_config()
            self.server_configs = mcp_config["servers"]

            if not self.server_configs:
                print("âŒ æ²¡æœ‰é…ç½®MCPæœåŠ¡å™¨")
                return False

            print("ğŸ”— æ­£åœ¨è¿æ¥MCPæœåŠ¡å™¨...")
            
            # å…ˆæµ‹è¯•æœåŠ¡å™¨è¿æ¥
            import aiohttp
            import asyncio
            
            for server_name, server_config in self.server_configs.items():
                try:
                    print(f"ğŸ§ª æµ‹è¯•è¿æ¥åˆ° {server_name}: {server_config['url']}")
                    async with aiohttp.ClientSession() as session:
                        async with session.get(server_config['url'], timeout=aiohttp.ClientTimeout(total=10)) as response:
                            print(f"âœ… {server_name} è¿æ¥æµ‹è¯•æˆåŠŸ (çŠ¶æ€: {response.status})")
                except Exception as test_e:
                    print(f"âš ï¸ {server_name} è¿æ¥æµ‹è¯•å¤±è´¥: {test_e}")
            
            # åˆ›å»ºMCPå®¢æˆ·ç«¯ - å¼ºåˆ¶æ¸…é™¤ç¼“å­˜å¹¶ç¦ç”¨HTTP/2
            import httpx

            def http_client_factory(headers=None, timeout=None, auth=None):
                return httpx.AsyncClient(
                    http2=False,  # ç¦ç”¨HTTP/2
                    headers=headers,
                    timeout=timeout,
                    auth=auth
                )

            # æ›´æ–°æœåŠ¡å™¨é…ç½®ä»¥ä½¿ç”¨è‡ªå®šä¹‰çš„httpxå®¢æˆ·ç«¯å·¥å‚
            for server_name in self.server_configs:
                self.server_configs[server_name]['httpx_client_factory'] = http_client_factory

            self.mcp_client = MultiServerMCPClient(self.server_configs)

            # æ”¹ä¸ºä¸²è¡Œè·å–å·¥å…·ï¼Œé¿å…å¹¶å‘é—®é¢˜
            print("ğŸ”§ æ­£åœ¨é€ä¸ªè·å–æœåŠ¡å™¨å·¥å…·...")
            for server_name in self.server_configs.keys():
                try:
                    print(f"â”€â”€â”€ æ­£åœ¨ä»æœåŠ¡å™¨ '{server_name}' è·å–å·¥å…· â”€â”€â”€")
                    server_tools = await self.mcp_client.get_tools(server_name=server_name)
                    self.tools.extend(server_tools)
                    self.tools_by_server[server_name] = server_tools
                    print(f"âœ… ä» {server_name} è·å–åˆ° {len(server_tools)} ä¸ªå·¥å…·")
                except Exception as e:
                    print(f"âŒ ä»æœåŠ¡å™¨ '{server_name}' è·å–å·¥å…·å¤±è´¥: {e}")
                    self.tools_by_server[server_name] = []
            
            # éªŒè¯å·¥å…·æ¥æºï¼Œç¡®ä¿åªæœ‰é…ç½®æ–‡ä»¶ä¸­çš„æœåŠ¡å™¨
            print(f"ğŸ” é…ç½®çš„æœåŠ¡å™¨: {list(self.server_configs.keys())}")
            print(f"ğŸ” å®é™…è·å–åˆ°çš„å·¥å…·æ•°é‡: {len(self.tools)}")
            
            # åˆ†ç»„é€»è¾‘å·²åœ¨ä¸Šé¢çš„å¾ªç¯ä¸­å®Œæˆï¼Œæ— éœ€é¢å¤–è°ƒç”¨

            print(f"âœ… æˆåŠŸè¿æ¥ï¼Œè·å–åˆ° {len(self.tools)} ä¸ªå·¥å…·")
            print(f"ğŸ“Š æœåŠ¡å™¨åˆ†ç»„æƒ…å†µ: {dict((name, len(tools)) for name, tools in self.tools_by_server.items())}")

            # ç»‘å®šå·¥å…·åˆ°å¤§æ¨¡å‹
            self.llm = self.llm.bind_tools(self.tools)

            print("ğŸ¤– Web MCPæ™ºèƒ½åŠ©æ‰‹å·²å¯åŠ¨ï¼")
            return True

        except Exception as e:
            import traceback
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            print(f"ğŸ“‹ è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
            
            # å°è¯•æ¸…ç†å¯èƒ½çš„è¿æ¥
            if hasattr(self, 'mcp_client') and self.mcp_client:
                try:
                    await self.mcp_client.close()
                except:
                    pass
            return False

    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        now = datetime.now()
        current_date = now.strftime("%Yå¹´%mæœˆ%dæ—¥")
        current_weekday = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][now.weekday()]

        return f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥è°ƒç”¨MCPå·¥å…·æ¥å¸®åŠ©ç”¨æˆ·å®Œæˆå„ç§ä»»åŠ¡ã€‚

å½“å‰æ—¶é—´ä¿¡æ¯ï¼š
ğŸ“… ä»Šå¤©æ˜¯ï¼š{current_date} ({current_weekday})

å·¥ä½œåŸåˆ™ï¼š
1. ä»”ç»†åˆ†æç”¨æˆ·éœ€æ±‚
2. é€‰æ‹©åˆé€‚çš„å·¥å…·æ¥å®Œæˆä»»åŠ¡
3. æ¸…æ¥šåœ°è§£é‡Šæ“ä½œè¿‡ç¨‹å’Œç»“æœ
4. å¦‚æœé‡åˆ°é—®é¢˜ï¼Œæä¾›å…·ä½“çš„è§£å†³å»ºè®®

è¯·å§‹ç»ˆä»¥ç”¨æˆ·éœ€æ±‚ä¸ºä¸­å¿ƒï¼Œé«˜æ•ˆåœ°ä½¿ç”¨å¯ç”¨å·¥å…·ã€‚"""

    async def chat_stream(self, user_input: str) -> AsyncGenerator[Dict[str, Any], None]:
        """æµå¼å¤„ç†ç”¨æˆ·è¾“å…¥ - ä¸ºWebSocketæ¨é€ä¼˜åŒ–"""
        try:
            yield {"type": "status", "content": "å¼€å§‹åˆ†æç”¨æˆ·éœ€æ±‚..."}

            # æ„å»ºæ¶ˆæ¯å†å²
            messages = [
                {"role": "system", "content": self._get_system_prompt()},
                {"role": "user", "content": user_input}
            ]
            max_iterations = 10
            iteration = 0

            while iteration < max_iterations:
                iteration += 1

                yield {"type": "status", "content": f"ç¬¬ {iteration} è½®æ¨ç†..."}

                # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ¨ç†
                response = await self.llm.ainvoke(messages)

                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if hasattr(response, 'tool_calls') and response.tool_calls:
                    yield {
                        "type": "tool_plan",
                        "content": f"AIå†³å®šè°ƒç”¨ {len(response.tool_calls)} ä¸ªå·¥å…·",
                        "tool_count": len(response.tool_calls)
                    }

                    # ä¸²è¡Œæ‰§è¡Œæ¯ä¸ªå·¥å…·è°ƒç”¨
                    for i, tool_call in enumerate(response.tool_calls, 1):
                        tool_name = tool_call['name']
                        tool_args = tool_call['args']
                        tool_id = tool_call.get('id', f"call_{i}")

                        # æ¨é€å·¥å…·å¼€å§‹æ‰§è¡Œ
                        yield {
                            "type": "tool_start",
                            "tool_id": tool_id,
                            "tool_name": tool_name,
                            "tool_args": tool_args,
                            "progress": f"{i}/{len(response.tool_calls)}"
                        }

                        try:
                            # æŸ¥æ‰¾å¯¹åº”çš„å·¥å…·
                            target_tool = None
                            for tool in self.tools:
                                if tool.name == tool_name:
                                    target_tool = tool
                                    break

                            if target_tool is None:
                                error_msg = f"å·¥å…· '{tool_name}' æœªæ‰¾åˆ°"
                                yield {
                                    "type": "tool_error",
                                    "tool_id": tool_id,
                                    "error": error_msg
                                }
                                tool_result = f"é”™è¯¯: {error_msg}"
                            else:
                                # æ‰§è¡Œå·¥å…·
                                tool_result = await target_tool.ainvoke(tool_args)

                                # æ¨é€å·¥å…·æ‰§è¡Œç»“æœ
                                yield {
                                    "type": "tool_end",
                                    "tool_id": tool_id,
                                    "tool_name": tool_name,
                                    "result": str(tool_result)
                                }

                        except Exception as e:
                            error_msg = f"å·¥å…·æ‰§è¡Œå‡ºé”™: {e}"
                            yield {
                                "type": "tool_error",
                                "tool_id": tool_id,
                                "error": error_msg
                            }
                            tool_result = f"é”™è¯¯: {error_msg}"

                        # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
                        messages.append({
                            "role": "assistant",
                            "content": response.content or "",
                            "tool_calls": [tool_call]
                        })
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_id,
                            "name": tool_name,
                            "content": str(tool_result)
                        })

                    # ç»§ç»­ä¸‹ä¸€è½®æ¨ç†
                    continue

                else:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿™æ˜¯æœ€ç»ˆå›å¤
                    final_response = response.content or ""

                    # æµå¼æ¨é€æœ€ç»ˆå›å¤
                    yield {
                        "type": "ai_response_start",
                        "content": "AIæ­£åœ¨æ•´ç†å›å¤..."
                    }

                    # æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
                    chunk_size = 10
                    for i in range(0, len(final_response), chunk_size):
                        chunk = final_response[i:i + chunk_size]
                        yield {
                            "type": "ai_response_chunk",
                            "content": chunk
                        }
                        await asyncio.sleep(0.05)  # å°å»¶è¿Ÿæ¨¡æ‹Ÿæµå¼æ•ˆæœ

                    yield {
                        "type": "ai_response_end",
                        "content": final_response
                    }

                    return

            # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
            yield {
                "type": "error",
                "content": f"è¾¾åˆ°æœ€å¤§æ¨ç†è½®æ•° ({max_iterations})ï¼Œåœæ­¢æ‰§è¡Œ"
            }

        except Exception as e:
            yield {
                "type": "error",
                "content": f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {e}"
            }

    def get_tools_info(self) -> Dict[str, Any]:
        """è·å–å·¥å…·ä¿¡æ¯åˆ—è¡¨ï¼ŒæŒ‰MCPæœåŠ¡å™¨åˆ†ç»„"""
        if not self.tools_by_server:
            return {"servers": {}, "total_tools": 0, "server_count": 0}
        
        servers_info = {}
        total_tools = 0
        
        # æŒ‰æœåŠ¡å™¨åˆ†ç»„æ„å»ºå·¥å…·ä¿¡æ¯
        for server_name, server_tools in self.tools_by_server.items():
            tools_info = []
            
            for tool in server_tools:
                tool_info = {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": {},
                    "required": []
                }
                
                # è·å–å‚æ•°ä¿¡æ¯ - ä¼˜åŒ–ç‰ˆæœ¬
                try:
                    schema = None
                    
                    # æ–¹æ³•1: å°è¯•ä½¿ç”¨args_schema (LangChainå·¥å…·å¸¸ç”¨)
                    if hasattr(tool, 'args_schema') and tool.args_schema:
                        if isinstance(tool.args_schema, dict):
                            schema = tool.args_schema
                        elif hasattr(tool.args_schema, 'model_json_schema'):
                            schema = tool.args_schema.model_json_schema()
                    
                    # æ–¹æ³•2: å¦‚æœæ²¡æœ‰args_schemaï¼Œå°è¯•tool_call_schema
                    if not schema and hasattr(tool, 'tool_call_schema') and tool.tool_call_schema:
                        schema = tool.tool_call_schema
                    
                    # æ–¹æ³•3: æœ€åå°è¯•input_schema
                    if not schema and hasattr(tool, 'input_schema') and tool.input_schema:
                        if isinstance(tool.input_schema, dict):
                            schema = tool.input_schema
                        elif hasattr(tool.input_schema, 'model_json_schema'):
                            try:
                                schema = tool.input_schema.model_json_schema()
                            except:
                                pass
                    
                    # è§£æschema
                    if schema and isinstance(schema, dict):
                        if 'properties' in schema:
                            tool_info["parameters"] = schema['properties']
                            tool_info["required"] = schema.get('required', [])
                        elif 'type' in schema and schema.get('type') == 'object' and 'properties' in schema:
                            tool_info["parameters"] = schema['properties']
                            tool_info["required"] = schema.get('required', [])
                
                except Exception as e:
                    # å¦‚æœå‡ºé”™ï¼Œè‡³å°‘ä¿ç•™å·¥å…·çš„åŸºæœ¬ä¿¡æ¯
                    print(f"âš ï¸ è·å–å·¥å…· '{tool.name}' å‚æ•°ä¿¡æ¯å¤±è´¥: {e}")
                
                tools_info.append(tool_info)
            
            # æ·»åŠ æœåŠ¡å™¨ä¿¡æ¯
            servers_info[server_name] = {
                "name": server_name,
                "tools": tools_info,
                "tool_count": len(tools_info)
            }
            
            total_tools += len(tools_info)
        
        return {
            "servers": servers_info,
            "total_tools": total_tools,
            "server_count": len(servers_info)
        }

    async def close(self):
        """å…³é—­è¿æ¥"""
        try:
            if self.mcp_client and hasattr(self.mcp_client, 'close'):
                await self.mcp_client.close()
        except:
            pass